{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lecture du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5081, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "negative     2251\n",
       "objective    1703\n",
       "mixed         629\n",
       "positive      498\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "\n",
    "df = pd.read_csv('task3-train.csv', sep='\\t', header=None, skiprows=10)\n",
    "df1 = df.iloc[:,-2:] # get two lasts columns\n",
    "df1.columns = [\"text\",\"sentiment\"] # name columns\n",
    "print(df1.shape)\n",
    "df1.head(5)\n",
    "df1[\"sentiment\"].value_counts() # get each final class count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3688    Comment @LaManifPourTous est finalement parven...\n",
       "2591    Campagne électorale - La péréquation n’est pas...\n",
       "4689    Beau moment de joie avec nos #friends @KarineF...\n",
       "4856        La tête de jeanluclemoineofficiel ! &#x1f602;\n",
       "805     #Cahuzac est ré-auditionné le jour où l'AN vot...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Séparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data_train, data_test, sentiment_train, sentiment_test = train_test_split(df1.text, df1.sentiment, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1553)\t0.15370708455992704\n",
      "  (0, 1425)\t0.2257728969907708\n",
      "  (0, 1316)\t0.30029750450020937\n",
      "  (0, 1135)\t0.14187320594707978\n",
      "  (0, 878)\t0.27404810133713875\n",
      "  (0, 817)\t0.12450171478818253\n",
      "  (0, 696)\t0.10157305453304527\n",
      "  (0, 695)\t0.19204687063475565\n",
      "  (0, 611)\t0.15450608916470435\n",
      "  (0, 593)\t0.341700109765643\n",
      "  (0, 525)\t0.12127394693752779\n",
      "  (0, 328)\t0.3670924497915549\n",
      "  (0, 327)\t0.2887750100738234\n",
      "  (0, 295)\t0.27802689871002106\n",
      "  (0, 32)\t0.237106903357032\n",
      "  (0, 18)\t0.3249746029702383\n",
      "  (0, 7)\t0.2543197516100405\n",
      "  (1, 1465)\t0.23326931965412365\n",
      "  (1, 1071)\t0.18768118473086623\n",
      "  (1, 793)\t0.16399635027215453\n",
      "  (1, 696)\t0.1652131710485343\n",
      "  (1, 525)\t0.19725756433368086\n",
      "  (1, 322)\t0.2786658084827272\n",
      "  (1, 255)\t0.4958028267762585\n",
      "  (1, 70)\t0.5480845809352872\n",
      "  :\t:\n",
      "  (1523, 846)\t0.30598277699873927\n",
      "  (1523, 793)\t0.17001025100389633\n",
      "  (1523, 781)\t0.2782794213541902\n",
      "  (1523, 750)\t0.15792946230051308\n",
      "  (1523, 615)\t0.20004042278294942\n",
      "  (1523, 408)\t0.28932597381950165\n",
      "  (1523, 406)\t0.08646206203952125\n",
      "  (1523, 76)\t0.29112632649385545\n",
      "  (1524, 1525)\t0.32120051355708334\n",
      "  (1524, 1429)\t0.22601590359973903\n",
      "  (1524, 1316)\t0.2862506779322273\n",
      "  (1524, 1287)\t0.20381788948878285\n",
      "  (1524, 1208)\t0.3132849479861017\n",
      "  (1524, 1198)\t0.16885233020336052\n",
      "  (1524, 995)\t0.21805590928599777\n",
      "  (1524, 871)\t0.2842340650533089\n",
      "  (1524, 817)\t0.11867797676559518\n",
      "  (1524, 750)\t0.15116303031651804\n",
      "  (1524, 708)\t0.14576764423499436\n",
      "  (1524, 527)\t0.12107686251416841\n",
      "  (1524, 513)\t0.24669524935732742\n",
      "  (1524, 406)\t0.0827576255558894\n",
      "  (1524, 304)\t0.3170776316690317\n",
      "  (1524, 281)\t0.3362898865291668\n",
      "  (1524, 190)\t0.3362898865291668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,max_df = 0.8,sublinear_tf = True,use_idf = True)\n",
    "#vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(data_train)\n",
    "test_vectors = vectorizer.transform(data_test) # check difference\n",
    "\n",
    "##il faut obtenir l'id du test, et la prediction\n",
    "print(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.242496s; Prediction time: 0.388061s\n",
      "positive:  {'precision': 0.6363636363636364, 'recall': 0.3798449612403101, 'f1-score': 0.4757281553398058, 'support': 129}\n",
      "negative:  {'precision': 0.64472190692395, 'recall': 0.8114285714285714, 'f1-score': 0.7185325743200506, 'support': 700}\n",
      "mixed:  {'precision': 0.3055555555555556, 'recall': 0.059782608695652176, 'f1-score': 0.1, 'support': 184}\n",
      "objective:  {'precision': 0.7062146892655368, 'recall': 0.732421875, 'f1-score': 0.7190795781399808, 'support': 512}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report# Perform classification with SVM, kernel=linear\n",
    "\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "\n",
    "#Train Data vectors\n",
    "classifier_linear.fit(train_vectors, sentiment_train)\n",
    "t1 = time.time()\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1 #Results\n",
    "\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "\n",
    "print('positive: ', report['positive'])\n",
    "print('negative: ', report['negative'])\n",
    "print('mixed: ', report['mixed'])\n",
    "print('objective: ', report['objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'objective' ... 'objective' 'negative' 'negative']\n",
      "Training time: 11.518978s; Prediction time: 1.871441s\n",
      "positive:  {'precision': 0.8681318681318682, 'recall': 0.6345381526104418, 'f1-score': 0.7331786542923435, 'support': 498}\n",
      "negative:  {'precision': 0.7238857938718662, 'recall': 0.9235895157707685, 'f1-score': 0.8116338083154401, 'support': 2251}\n",
      "mixed:  {'precision': 0.8345864661654135, 'recall': 0.17647058823529413, 'f1-score': 0.2913385826771654, 'support': 629}\n",
      "objective:  {'precision': 0.8358644859813084, 'recall': 0.8402818555490311, 'f1-score': 0.8380673499267935, 'support': 1703}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Train on whole dataset\n",
    "train_vectors = vectorizer.fit_transform(df1.text)\n",
    "test_vector = vectorizer.fit_transform(df1.text)\n",
    "classifier_linear.fit(train_vectors, df1.sentiment)\n",
    "t1 = time.time()\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear.predict(test_vector)\n",
    "t2 = time.time()\n",
    "\n",
    "print(prediction_linear)\n",
    "\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1 #Results\n",
    "\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "\n",
    "print('positive: ', report['positive'])\n",
    "print('negative: ', report['negative'])\n",
    "print('mixed: ', report['mixed'])\n",
    "print('objective: ', report['objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 1, 0, 0]),\n",
       " Index(['negative', 'objective', 'positive', 'mixed'], dtype='object'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert categorical values to numeric with factorize()\n",
    "sentiment_label = df1.sentiment.factorize()\n",
    "sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Train de vie des ministères : Fillon conteste les chiffres Qui ment? () http://tinyurl.com/y89zgkk',\n",
       "       'Un complot sioniste pour augmenter les accidents mortels en Tunisie http://snipr.com/ua2dw',\n",
       "       \"[rp-fr][Numerama] La Chine rejoint l'Inde pour s'opposer à l'ACTA http://ur1.ca/05rxl\",\n",
       "       ...,\n",
       "       'Fabius : \"Ma vie politique est un échec terrible !\" #publicsenat http://bit.ly/guC3mm',\n",
       "       \"le gouvernement fait tout pour qu'on ne subisse pas le même sort que la Grèce, la preuve: #ok http://bit.ly/o1yaUJ\",\n",
       "       '#Chavez va mieux, il se remet à agresser les E.U, ouf, je suis rassuré http://goo.gl/YoOnb'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df1.text.values\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize, break down everything into words\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "\n",
    "tokenizer.fit_on_texts(tweet)\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(tweet)\n",
    "#Les phrases du dataSet n'ont pas la même longueur, Padding to pad pour avoir la même longueur\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
