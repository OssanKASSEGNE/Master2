{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3_Ossan_Noémie_Yosr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture du fichier csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Création d'un dataFrame tweet et sentiment, on ignore les 10 premières lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('task3-train.csv', sep='\\t', header=None, skiprows=10,quoting=csv.QUOTE_NONE)\n",
    "print(len(df))\n",
    "df1 = df.iloc[:,-2:] # get two lasts columns\n",
    "df1.columns = [\"text\",\"sentiment\"] # name columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation du corpus (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, sentiment_train, sentiment_test = train_test_split(df1.text, df1.sentiment, test_size=0.2,random_state=109) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Utilisation de BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(data_train)\n",
    "test_vectors = vectorizer.transform(data_test) # check difference\n",
    "##il faut obtenir l'id du test, et la prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle à partir des données d'apprentissages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonction analyse de résultats\n",
    "def analyse(report):\n",
    "    for key in report:\n",
    "        print(key,'->',report[key])\n",
    "        if key == 'accuracy':\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boucle1 SVM TFIDF sans nettoyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.22807017543859648, 'recall': 0.2, 'f1-score': 0.21311475409836067, 'support': 130}\n",
      "negative -> {'precision': 0.6462882096069869, 'recall': 0.6548672566371682, 'f1-score': 0.6505494505494507, 'support': 452}\n",
      "objective -> {'precision': 0.6781002638522428, 'recall': 0.7259887005649718, 'f1-score': 0.7012278308321964, 'support': 354}\n",
      "positive -> {'precision': 0.5616438356164384, 'recall': 0.4659090909090909, 'f1-score': 0.5093167701863354, 'support': 88}\n",
      "accuracy -> 0.60546875\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train Data vectors\n",
    "classifier_linear.fit(train_vectors, sentiment_train)\n",
    "\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "\n",
    "fullReport = {'Raw bag of word SVM' : report}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle à partir du corpus complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.9984177215189873, 'recall': 0.9968404423380727, 'f1-score': 0.9976284584980237, 'support': 633}\n",
      "negative -> {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2263}\n",
      "objective -> {'precision': 0.9988365328679465, 'recall': 0.9994179278230501, 'f1-score': 0.999127145766657, 'support': 1718}\n",
      "positive -> {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 504}\n",
      "accuracy -> 0.9994138335287222\n"
     ]
    }
   ],
   "source": [
    "#Train on whole dataset\n",
    "train_vectors = vectorizer.fit_transform(df1.text)\n",
    "test_vector = vectorizer.transform(df1.text)\n",
    "classifier_linear.fit(train_vectors, df1.sentiment)\n",
    "\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear.predict(test_vector)\n",
    "\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run2 with TFIDF / SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.3125, 'recall': 0.038461538461538464, 'f1-score': 0.06849315068493152, 'support': 130}\n",
      "negative -> {'precision': 0.6378091872791519, 'recall': 0.7986725663716814, 'f1-score': 0.7092337917485265, 'support': 452}\n",
      "objective -> {'precision': 0.7097625329815304, 'recall': 0.7598870056497176, 'f1-score': 0.7339699863574352, 'support': 354}\n",
      "positive -> {'precision': 0.6190476190476191, 'recall': 0.4431818181818182, 'f1-score': 0.5165562913907285, 'support': 88}\n",
      "accuracy -> 0.658203125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer1 = TfidfVectorizer(min_df = 1,max_df = 0.9,sublinear_tf = True,use_idf = True)\n",
    "train_vectors = vectorizer1.fit_transform(data_train)\n",
    "test_vectors = vectorizer1.transform(data_test) # check difference\n",
    "##il faut obtenir l'id du test, et la prediction\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear1 = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train Data vectors\n",
    "classifier_linear1.fit(train_vectors, sentiment_train)\n",
    "\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear1.predict(test_vectors)\n",
    "\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "fullReport['Raw tfidf SVM'] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.9705882352941176, 'recall': 0.46919431279620855, 'f1-score': 0.6325878594249201, 'support': 633}\n",
      "negative -> {'precision': 0.8234415826801045, 'recall': 0.9748121961997349, 'f1-score': 0.8927559692432213, 'support': 2263}\n",
      "objective -> {'precision': 0.9225393127548049, 'recall': 0.9220023282887078, 'f1-score': 0.9222707423580786, 'support': 1718}\n",
      "positive -> {'precision': 0.9567307692307693, 'recall': 0.7896825396825397, 'f1-score': 0.8652173913043478, 'support': 504}\n",
      "accuracy -> 0.8763188745603752\n"
     ]
    }
   ],
   "source": [
    "#Train on whole dataset\n",
    "train_vectorsFinal = vectorizer1.fit_transform(df1.text)\n",
    "test_vectorsFinal = vectorizer1.transform(df1.text)\n",
    "\n",
    "classifier_linear1.fit(train_vectorsFinal, df1.sentiment)\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear1.predict(test_vectorsFinal)\n",
    "# Résultat\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run3 Stop words (French dictionary) / with TFIDF / SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.25, 'recall': 0.03076923076923077, 'f1-score': 0.05479452054794521, 'support': 130}\n",
      "negative -> {'precision': 0.6309090909090909, 'recall': 0.7676991150442478, 'f1-score': 0.6926147704590818, 'support': 452}\n",
      "objective -> {'precision': 0.6910994764397905, 'recall': 0.7457627118644068, 'f1-score': 0.7173913043478262, 'support': 354}\n",
      "positive -> {'precision': 0.5789473684210527, 'recall': 0.5, 'f1-score': 0.5365853658536586, 'support': 88}\n",
      "accuracy -> 0.6435546875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1941    La plus grande erreur que jai faite durant ma ...\n",
       "1688    La Russie crée un ministère chargé de la Crimé...\n",
       "1045    Lorsque que Obama aura une rencontre avec Maro...\n",
       "3087    \"Avons nous des nouvelles de Léonarda?\" Dernie...\n",
       "1198    Tjs qd qu'il est au cabinet du Min. de la Cult...\n",
       "                              ...                        \n",
       "2635    #Hollande annonce une réduction d'impôts ... s...\n",
       "2447    Racisme, chantages,... Des raisons pour ne plu...\n",
       "141     \"Je n'accepterai pas de leçons de morale d'une...\n",
       "3317    Actu. Afrique - Cameroun : les États-Unis dépl...\n",
       "3334    Quand Barack Obama débarque dans une cérémonie...\n",
       "Name: text, Length: 4094, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = stopwords.words('french')\n",
    "# max_df ignorer les mot qui apparaisent dans plus de 90% du document\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(min_df = 1,max_df = 0.9,sublinear_tf = True,use_idf = True, stop_words=stop_words_list)\n",
    "\n",
    "train_vectors = vectorizer2.fit_transform(data_train)\n",
    "test_vectors = vectorizer2.transform(data_test) # check difference\n",
    "##il faut obtenir l'id du test, et la prediction\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear2 = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train Data vectors\n",
    "classifier_linear2.fit(train_vectors, sentiment_train)\n",
    "\n",
    "\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear2.predict(test_vectors)\n",
    "\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "fullReport['StopWords tfidf SVM'] = report\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.9850299401197605, 'recall': 0.5197472353870458, 'f1-score': 0.6804550155118926, 'support': 633}\n",
      "negative -> {'precision': 0.8333333333333334, 'recall': 0.9721608484312859, 'f1-score': 0.8974097491331837, 'support': 2263}\n",
      "objective -> {'precision': 0.9253903990746096, 'recall': 0.9313154831199069, 'f1-score': 0.9283434870902234, 'support': 1718}\n",
      "positive -> {'precision': 0.9566265060240964, 'recall': 0.7876984126984127, 'f1-score': 0.8639825897714909, 'support': 504}\n",
      "accuracy -> 0.8843298163345057\n"
     ]
    }
   ],
   "source": [
    "#Train on whole dataset\n",
    "train_vectorsFinal = vectorizer2.fit_transform(df1.text)\n",
    "test_vectorsFinal = vectorizer2.transform(df1.text)\n",
    "\n",
    "classifier_linear2.fit(train_vectorsFinal, df1.sentiment)\n",
    "#Prediction\n",
    "prediction_linear = classifier_linear2.predict(test_vectorsFinal)\n",
    "# Résultat\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run3 moins performant que Run2, trop de stopwords supprimé ce qui explique la mauvaise performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prétraitements de données, suppression de stopwords avec lemmatization and stemming\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "stemmer = FrenchStemmer()\n",
    "\n",
    "def pretraitement(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove url\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", text)\n",
    "    # Remove punctuation\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    text = tokenizer.tokenize(text)\n",
    "    # Remove French stopwords and punctuation \n",
    "    tokenized_word = text\n",
    "    filtered_sent=[]\n",
    "    for w in tokenized_word:\n",
    "        if w not in stop_words_list:\n",
    "            filtered_sent.append(w)\n",
    "    text = ' '.join(filtered_sent)  \n",
    "    # lemmatization and stemming\n",
    "    return \" \".join([stemmer.stem(token.lemma_) for token in nlp(text)])\n",
    "\n",
    "# Remplacement par le dataFrame propre\n",
    "df1['text'] = df1['text'].to_frame().applymap(pretraitement)\n",
    "\n",
    "\n",
    "# Séparation du corpus prétraité\n",
    "data_train, data_test, sentiment_train, sentiment_test = train_test_split(df1.text, df1.sentiment, test_size=0.2,random_state=109)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM TFIDF NGramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.5, 'recall': 0.023076923076923078, 'f1-score': 0.04411764705882353, 'support': 130}\n",
      "negative -> {'precision': 0.6070234113712375, 'recall': 0.8030973451327433, 'f1-score': 0.6914285714285714, 'support': 452}\n",
      "objective -> {'precision': 0.6835820895522388, 'recall': 0.6468926553672316, 'f1-score': 0.6647314949201742, 'support': 354}\n",
      "positive -> {'precision': 0.5294117647058824, 'recall': 0.5113636363636364, 'f1-score': 0.5202312138728323, 'support': 88}\n",
      "accuracy -> 0.625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1941    plus grand erreur jai fair dur scolarit demand...\n",
       "1688            russ cré minister charg crim soviet oeuvr\n",
       "1045          lorsqu obam rencontr marois poul dent polqc\n",
       "3087    nouveau léonard derni mot françois holland ava...\n",
       "1198    tj qd cabinet min cultur sous sarkozy mathieu ...\n",
       "                              ...                        \n",
       "2635    holland annonc réduct impôt sûr 0 1 dir cel av...\n",
       "2447    racism chantag raison plus lir jeun afriqu mic...\n",
       "141     accept leçon moral gauch vouloir install dsk e...\n",
       "3317    actu afriqu cameroun état unir déploient 300 m...\n",
       "3334    quand barack obam débarqu cérémon mariag vi la...\n",
       "Name: text, Length: 4094, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Principale Vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 1,max_df = 0.9,sublinear_tf = True,use_idf = True, ngram_range=(1,3))\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(data_train)\n",
    "test_vectors = vectorizer.transform(data_test) \n",
    "\n",
    "##il faut obtenir l'id du test, et la prediction\n",
    "# Perform classification with SVM, kernel=linear\n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "#Train Data vectors\n",
    "svm_linear.fit(train_vectors, sentiment_train)\n",
    "#Prediction\n",
    "prediction_linear = svm_linear.predict(test_vectors)\n",
    "# Résultat\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "fullReport['Clean tfidf SVM Ngram'] = report\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.9983471074380166, 'recall': 0.9541864139020537, 'f1-score': 0.975767366720517, 'support': 633}\n",
      "negative -> {'precision': 0.9821038847664775, 'recall': 0.9942554131683606, 'f1-score': 0.9881422924901185, 'support': 2263}\n",
      "objective -> {'precision': 0.9816091954022989, 'recall': 0.9941792782305006, 'f1-score': 0.9878542510121459, 'support': 1718}\n",
      "positive -> {'precision': 0.995850622406639, 'recall': 0.9523809523809523, 'f1-score': 0.973630831643002, 'support': 504}\n",
      "accuracy -> 0.9851504493942946\n"
     ]
    }
   ],
   "source": [
    "#Train on whole dataset\n",
    "train_vectorsFinal = vectorizer.fit_transform(df1.text)\n",
    "test_vectorsFinal = vectorizer.transform(df1.text)\n",
    "\n",
    "svm_linear.fit(train_vectorsFinal, df1.sentiment)\n",
    "#Prediction\n",
    "prediction_linear = svm_linear.predict(test_vectorsFinal)\n",
    "# Résultat\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baiyes TFIDF NGramms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.13861386138613863, 'recall': 0.1076923076923077, 'f1-score': 0.12121212121212122, 'support': 130}\n",
      "negative -> {'precision': 0.6033057851239669, 'recall': 0.6460176991150443, 'f1-score': 0.623931623931624, 'support': 452}\n",
      "objective -> {'precision': 0.6303724928366762, 'recall': 0.6214689265536724, 'f1-score': 0.6258890469416786, 'support': 354}\n",
      "positive -> {'precision': 0.4, 'recall': 0.4090909090909091, 'f1-score': 0.40449438202247195, 'support': 88}\n",
      "accuracy -> 0.548828125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#création d'un classifieur Gaussian\n",
    "gnb = GaussianNB()\n",
    "#entrainement\n",
    "gnb.fit(train_vectors.toarray(), sentiment_train)\n",
    "#Prediction\n",
    "prediction_linear = gnb.predict(test_vectors.toarray())\n",
    "# Résultat\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "fullReport['Clean tfidf baiyes Ngram'] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.9890453834115805, 'recall': 0.9984202211690363, 'f1-score': 0.9937106918238993, 'support': 633}\n",
      "negative -> {'precision': 1.0, 'recall': 0.999116217410517, 'f1-score': 0.9995579133510168, 'support': 2263}\n",
      "objective -> {'precision': 0.9994158878504673, 'recall': 0.9959254947613504, 'f1-score': 0.9976676384839651, 'support': 1718}\n",
      "positive -> {'precision': 0.9960474308300395, 'recall': 1.0, 'f1-score': 0.998019801980198, 'support': 504}\n",
      "accuracy -> 0.9980461117624072\n"
     ]
    }
   ],
   "source": [
    "#entrainement\n",
    "gnb.fit(train_vectorsFinal.toarray(), df1.sentiment)\n",
    "#Prediction\n",
    "prediction_linear = gnb.predict(test_vectorsFinal.toarray())\n",
    "# Résultat\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN TFIDF unigrams bigramm, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.17105263157894737, 'recall': 0.1, 'f1-score': 0.1262135922330097, 'support': 130}\n",
      "negative -> {'precision': 0.6206896551724138, 'recall': 0.5973451327433629, 'f1-score': 0.608793686583991, 'support': 452}\n",
      "objective -> {'precision': 0.5815602836879432, 'recall': 0.6949152542372882, 'f1-score': 0.6332046332046332, 'support': 354}\n",
      "positive -> {'precision': 0.45555555555555555, 'recall': 0.4659090909090909, 'f1-score': 0.4606741573033708, 'support': 88}\n",
      "accuracy -> 0.556640625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# création d'un classifieur Gaussian\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# entrainement\n",
    "knn.fit(train_vectors, sentiment_train)\n",
    "# Prediction\n",
    "prediction_linear = knn.predict(test_vectors.toarray())\n",
    "# Résultat\n",
    "report = classification_report(sentiment_test, prediction_linear, output_dict=True)\n",
    "analyse(report)\n",
    "fullReport['Clean tfidf KNN Ngram'] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed -> {'precision': 0.558252427184466, 'recall': 0.36334913112164297, 'f1-score': 0.4401913875598086, 'support': 633}\n",
      "negative -> {'precision': 0.7573626373626373, 'recall': 0.7613787008395935, 'f1-score': 0.7593653591890701, 'support': 2263}\n",
      "objective -> {'precision': 0.7026627218934911, 'recall': 0.829452852153667, 'f1-score': 0.7608115323011211, 'support': 1718}\n",
      "positive -> {'precision': 0.7245657568238213, 'recall': 0.5793650793650794, 'f1-score': 0.6438809261300993, 'support': 504}\n",
      "accuracy -> 0.7170769831965611\n"
     ]
    }
   ],
   "source": [
    "#entrainement\n",
    "knn.fit(train_vectorsFinal, df1.sentiment)\n",
    "#Prediction\n",
    "prediction_linear = knn.predict(test_vectorsFinal)\n",
    "# Résultat\n",
    "report = classification_report(df1.sentiment, prediction_linear, output_dict=True)\n",
    "analyse(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw bag of word SVM</th>\n",
       "      <th>Raw tfidf SVM</th>\n",
       "      <th>StopWords tfidf SVM</th>\n",
       "      <th>Clean tfidf SVM Ngram</th>\n",
       "      <th>Clean tfidf baiyes Ngram</th>\n",
       "      <th>Clean tfidf KNN Ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixed</th>\n",
       "      <td>{'precision': 0.22807017543859648, 'recall': 0...</td>\n",
       "      <td>{'precision': 0.3125, 'recall': 0.038461538461...</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.03076923076923...</td>\n",
       "      <td>{'precision': 0.5, 'recall': 0.023076923076923...</td>\n",
       "      <td>{'precision': 0.13861386138613863, 'recall': 0...</td>\n",
       "      <td>{'precision': 0.17105263157894737, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>{'precision': 0.6462882096069869, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6378091872791519, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6309090909090909, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6070234113712375, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6033057851239669, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6206896551724138, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>{'precision': 0.6781002638522428, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.7097625329815304, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6910994764397905, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6835820895522388, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6303724928366762, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5815602836879432, 'recall': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>{'precision': 0.5616438356164384, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6190476190476191, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5789473684210527, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5294117647058824, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.409090909090909...</td>\n",
       "      <td>{'precision': 0.45555555555555555, 'recall': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>0.643555</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.548828</td>\n",
       "      <td>0.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'precision': 0.5285256211285662, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5697798348270753, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5377389839424835, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5800043164073396, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.44307303483669547, 'recall': 0...</td>\n",
       "      <td>{'precision': 0.457214531498715, 'recall': 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'precision': 0.5969175239133946, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6197723435564736, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5988940353238745, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.6132332782572358, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5361971477738423, 'recall': 0....</td>\n",
       "      <td>{'precision': 0.5358884722242334, 'recall': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Raw bag of word SVM  \\\n",
       "mixed         {'precision': 0.22807017543859648, 'recall': 0...   \n",
       "negative      {'precision': 0.6462882096069869, 'recall': 0....   \n",
       "objective     {'precision': 0.6781002638522428, 'recall': 0....   \n",
       "positive      {'precision': 0.5616438356164384, 'recall': 0....   \n",
       "accuracy                                               0.605469   \n",
       "macro avg     {'precision': 0.5285256211285662, 'recall': 0....   \n",
       "weighted avg  {'precision': 0.5969175239133946, 'recall': 0....   \n",
       "\n",
       "                                                  Raw tfidf SVM  \\\n",
       "mixed         {'precision': 0.3125, 'recall': 0.038461538461...   \n",
       "negative      {'precision': 0.6378091872791519, 'recall': 0....   \n",
       "objective     {'precision': 0.7097625329815304, 'recall': 0....   \n",
       "positive      {'precision': 0.6190476190476191, 'recall': 0....   \n",
       "accuracy                                               0.658203   \n",
       "macro avg     {'precision': 0.5697798348270753, 'recall': 0....   \n",
       "weighted avg  {'precision': 0.6197723435564736, 'recall': 0....   \n",
       "\n",
       "                                            StopWords tfidf SVM  \\\n",
       "mixed         {'precision': 0.25, 'recall': 0.03076923076923...   \n",
       "negative      {'precision': 0.6309090909090909, 'recall': 0....   \n",
       "objective     {'precision': 0.6910994764397905, 'recall': 0....   \n",
       "positive      {'precision': 0.5789473684210527, 'recall': 0....   \n",
       "accuracy                                               0.643555   \n",
       "macro avg     {'precision': 0.5377389839424835, 'recall': 0....   \n",
       "weighted avg  {'precision': 0.5988940353238745, 'recall': 0....   \n",
       "\n",
       "                                          Clean tfidf SVM Ngram  \\\n",
       "mixed         {'precision': 0.5, 'recall': 0.023076923076923...   \n",
       "negative      {'precision': 0.6070234113712375, 'recall': 0....   \n",
       "objective     {'precision': 0.6835820895522388, 'recall': 0....   \n",
       "positive      {'precision': 0.5294117647058824, 'recall': 0....   \n",
       "accuracy                                                  0.625   \n",
       "macro avg     {'precision': 0.5800043164073396, 'recall': 0....   \n",
       "weighted avg  {'precision': 0.6132332782572358, 'recall': 0....   \n",
       "\n",
       "                                       Clean tfidf baiyes Ngram  \\\n",
       "mixed         {'precision': 0.13861386138613863, 'recall': 0...   \n",
       "negative      {'precision': 0.6033057851239669, 'recall': 0....   \n",
       "objective     {'precision': 0.6303724928366762, 'recall': 0....   \n",
       "positive      {'precision': 0.4, 'recall': 0.409090909090909...   \n",
       "accuracy                                               0.548828   \n",
       "macro avg     {'precision': 0.44307303483669547, 'recall': 0...   \n",
       "weighted avg  {'precision': 0.5361971477738423, 'recall': 0....   \n",
       "\n",
       "                                          Clean tfidf KNN Ngram  \n",
       "mixed         {'precision': 0.17105263157894737, 'recall': 0...  \n",
       "negative      {'precision': 0.6206896551724138, 'recall': 0....  \n",
       "objective     {'precision': 0.5815602836879432, 'recall': 0....  \n",
       "positive      {'precision': 0.45555555555555555, 'recall': 0...  \n",
       "accuracy                                               0.556641  \n",
       "macro avg     {'precision': 0.457214531498715, 'recall': 0.4...  \n",
       "weighted avg  {'precision': 0.5358884722242334, 'recall': 0....  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullReport = pd.DataFrame.from_dict(fullReport)\n",
    "fullReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests avec Tweet non annotés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creation a predictioncsv file\n",
    "def predict(inputFile,outputFile, vectorizer, model):\n",
    "    ## Get DataFrame from csv file (column => id tweet)\n",
    "    dfTest = pd.read_csv('task3-test.csv',\n",
    "                   delimiter='\\t',\n",
    "                   header=None,\n",
    "                   names=['tweet_x', 'sentiment_x'],quoting=csv.QUOTE_NONE)\n",
    "\n",
    "    dfTestTweet = dfTest.iloc[:,-1:] # get the last column => tweet\n",
    "    dfTestTweet = dfTestTweet.iloc[:,0] # Turn into panda Series\n",
    "    \n",
    "    #Vecteur des ids numpy array str\n",
    "    dfTestId = ((dfTest.iloc[:,0]).to_numpy()).astype(str)\n",
    "    #Création du vecteur de données tests\n",
    "    dfTestTweet = dfTestTweet.to_frame().applymap(pretraitement)\n",
    "    # convert to series for the vectorizer\n",
    "    dfTestTweet.columns = ['data']\n",
    "    test_vectors = vectorizer.transform(dfTestTweet['data']) \n",
    "    \n",
    "    #Prediction\n",
    "    if model == gnb:\n",
    "       prediction = model.predict(test_vectors.toarray()) \n",
    "    else:\n",
    "        prediction = model.predict(test_vectors)\n",
    "   \n",
    "    #Create file lines \n",
    "    for i in range(dfTestId.size):\n",
    "        dfTestId[i]= \"(\" + dfTestId[i] + \")\"\n",
    "        \n",
    "    matrix = np.column_stack((prediction,dfTestId))\n",
    "    \n",
    "    #Create the file\n",
    "    np.savetxt(outputFile, matrix ,fmt='%s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDP => Changer le nom du fichier csv et le classifier\n",
    "predict('task3-test.csv','task3_KassegneOssan_run1.sc', vectorizer,svm_linear)\n",
    "predict('task3-test.csv','task3_KassegneOssan_run2.sc', vectorizer1,classifier_linear1)\n",
    "predict('task3-test.csv','task3_KassegneOssan_run3.sc', vectorizer2,classifier_linear2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
